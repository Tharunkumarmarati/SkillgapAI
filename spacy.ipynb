{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a877d340-2fa8-4178-a772-07da339297ee",
   "metadata": {},
   "source": [
    "# spaCy Pipeline (Rule-Based + Matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceaaabe-90e5-4be0-a30d-584deb651b19",
   "metadata": {},
   "source": [
    "### 1. Install spaCy and load the en_core_web_sm model using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7778958-55e7-47e0-ad5a-caf60d21aa0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (3.8.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (2.12.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (78.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tarun\\anaconda3\\envs\\maratitharunkumar\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff60c521-d778-4b82-aea5-98fa96fad11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 8.2 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 7.6 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.0/12.8 MB 7.8 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.6/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.4/12.8 MB 7.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 8.0 MB/s  0:00:01\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06b5155-4328-4d7c-8d0c-d2dc6f19e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import json\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def normalize_skills(skill_list):\n",
    "    return sorted(set(skill.lower() for skill in skill_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4c5cb-7719-49c9-9e92-4cc37b849b43",
   "metadata": {},
   "source": [
    "### 2. Using PhraseMatcher, extract the skills Python and SQL from the text: 'I have experience in Python and SQL.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fdf6f3-d426-4a72-9fa7-e1c58a48304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")  # case-insensitive\n",
    "skills_basic = [\"Python\", \"SQL\"]\n",
    "patterns = [nlp.make_doc(skill) for skill in skills_basic]\n",
    "matcher.add(\"BASIC_SKILLS\", patterns)\n",
    "\n",
    "text_1 = \"I have experience in Python and SQL.\"\n",
    "doc_1 = nlp(text_1)\n",
    "\n",
    "extracted_skills_1 = [doc_1[start:end].text for _, start, end in matcher(doc_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d13851-4415-4c63-88ae-927cafef5a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'SQL']\n"
     ]
    }
   ],
   "source": [
    "print(extracted_skills_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bd8a2-c620-4390-975c-ccc8bf704593",
   "metadata": {},
   "source": [
    "### 3. Create a Python list of five technical skills and convert them into PhraseMatcher patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c8d76ca-3cb1-49ef-b58b-a7e5900144ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_skills = ['Python','SQL','Machine Learning','Java','NLP']\n",
    "tech_patterns = [nlp.make_doc(skill) for skill in tech_skills]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d364f342-076f-46ed-8053-9678ac3e018b",
   "metadata": {},
   "source": [
    "### 4. Write code to convert all extracted skills into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "446999e9-5750-4b16-b0c8-34d6def511fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'sql']\n"
     ]
    }
   ],
   "source": [
    "lower_cased = []\n",
    "def lower_case(extracted_skills_1):\n",
    "    for i in extracted_skills_1:\n",
    "        lower_cased.append(i.lower())\n",
    "lower_case(extracted_skills_1)\n",
    "print(lower_cased)\n",
    "extracted_skills = lower_cased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e6a1a3-32d3-4b85-8ce4-c994dd03ed54",
   "metadata": {},
   "source": [
    "### 5. Remove duplicate skills from a list of extracted skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48a5f47c-e7ac-4a10-9825-123daa7114aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sql', 'python'}\n",
      "['sql', 'python']\n"
     ]
    }
   ],
   "source": [
    "extracted_skills = set(extracted_skills)\n",
    "print(extracted_skills)\n",
    "extracted_skills = list(extracted_skills)\n",
    "print(extracted_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb90ad6-95ac-4e22-a67a-187b6eb844b7",
   "metadata": {},
   "source": [
    "### 6. Extract technical skills from the sentence: 'Experience in Python, NLP, and Machine Learning with SQL.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d40feda-b674-444d-8f3b-796477be45f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine learning', 'nlp', 'python', 'sql']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher_tech = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "matcher_tech.add(\"TECH_SKILLS\", tech_patterns)\n",
    "\n",
    "text_2 = \"Experience in Python, NLP, and Machine Learning with SQL.\"\n",
    "doc_2 = nlp(text_2)\n",
    "\n",
    "tech_extracted_2 = normalize_skills(\n",
    "    [doc_2[start:end].text for _, start, end in matcher_tech(doc_2)]\n",
    ")\n",
    "tech_extracted_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f8b36-33b6-487f-a511-558730073ddd",
   "metadata": {},
   "source": [
    "### 7. Identify soft skills from a resume text using token comparison and a predefined soft skill list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05de324c-7d63-406f-868b-b2c7bd00c4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['communication', 'leadership', 'teamwork']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_skill_list = [\n",
    "    \"communication\",\n",
    "    \"teamwork\",\n",
    "    \"leadership\",\n",
    "    \"problem solving\",\n",
    "    \"time management\"\n",
    "]\n",
    "\n",
    "def extract_soft_skills(text):\n",
    "    doc = nlp(text.lower())\n",
    "    found = []\n",
    "    for skill in soft_skill_list:\n",
    "        if skill in doc.text:\n",
    "            found.append(skill)\n",
    "    return normalize_skills(found)\n",
    "\n",
    "resume_text_soft = \"Strong communication and teamwork skills with leadership qualities.\"\n",
    "soft_skills_extracted = extract_soft_skills(resume_text_soft)\n",
    "soft_skills_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af3180-5c70-44d5-827b-1f9f8555a819",
   "metadata": {},
   "source": [
    "### 8. Configure PhraseMatcher to perform case-insensitive matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6665f956-3575-4c0e-b241-c47e779da8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher2 = PhraseMatcher(nlp.vocab, attr = 'LOWER')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af7e276-316f-4bc0-ae92-b4ac96671420",
   "metadata": {},
   "source": [
    "### 9. Store extracted technical and soft skills in the JSON structure: { technical_skills: [], soft_skills: [] }."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61afaa83-b34c-4c14-baf5-37766ce6eed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'technical_skills': ['machine learning', 'nlp', 'python', 'sql'],\n",
       " 'soft_skills': ['communication', 'leadership', 'teamwork']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_struct = {\n",
    "    'technical_skills':tech_extracted_2,\n",
    "    'soft_skills':soft_skills_extracted\n",
    "}\n",
    "json_struct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569865c0-3f51-4efe-b4df-9ecab128b663",
   "metadata": {},
   "source": [
    "### 10. Extract skills from a paragraph that contains repeated skill mentions and ensure duplicates are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "980552bb-c428-460f-af6f-371c8d88e744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'sql']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_3 = \"Python, Python, SQL and SQL are required.\"\n",
    "doc_3 = nlp(text_3)\n",
    "\n",
    "tech_extracted_3 = normalize_skills(\n",
    "    [doc_3[start:end].text for _, start, end in matcher_tech(doc_3)]\n",
    ")\n",
    "tech_extracted_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8845bf4-696e-4353-94e9-49ac11a6e61a",
   "metadata": {},
   "source": [
    "### 11. Ensure skills are correctly extracted from text containing punctuation such as commas and semicolons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12b4f51d-a435-459b-a429-edf9e1288086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine learning', 'nlp', 'python', 'sql']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_4 = \"Required skills: Python; SQL, NLP, and Machine Learning.\"\n",
    "doc_4 = nlp(text_4)\n",
    "\n",
    "tech_extracted_4 = normalize_skills(\n",
    "    [doc_4[start:end].text for _, start, end in matcher_tech(doc_4)]\n",
    ")\n",
    "tech_extracted_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a2a4e-2ef5-4d38-8395-fd2bee3729b5",
   "metadata": {},
   "source": [
    "### 12. Combine PhraseMatcher for technical skills and rule-based token matching for soft skills in a single spaCy pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b9ec6cc-359e-45b7-886c-362dabdae53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_skills(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tech = normalize_skills(\n",
    "        [doc[start:end].text for _, start, end in matcher_tech(doc)]\n",
    "    )\n",
    "    soft = extract_soft_skills(text)\n",
    "\n",
    "    return {\n",
    "        \"technical_skills\": tech,\n",
    "        \"soft_skills\": soft\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f00fe-b60d-41f8-b94f-922844b8f97a",
   "metadata": {},
   "source": [
    "### 13. Extract skills from multiple sentences and merge them into one normalized output dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ab82b5e-53d1-4ef3-bfb8-7bb7a5d4d04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'technical_skills': ['nlp', 'python', 'sql'],\n",
       " 'soft_skills': ['communication', 'teamwork']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_sentence_text = \"\"\"\n",
    "I have experience in Python and SQL.\n",
    "I also worked on NLP projects.\n",
    "Strong communication and teamwork skills.\n",
    "\"\"\"\n",
    "\n",
    "skills_multi = extract_all_skills(multi_sentence_text)\n",
    "skills_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025558a2-743c-4880-977f-5dc05759581d",
   "metadata": {},
   "source": [
    "### 14. Modify skill extraction logic to match SQL but not NoSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afcbfdd0-6671-45e8-916c-d02eb1e15dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sql']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "sql_matcher.add(\"SQL_ONLY\", [nlp.make_doc(\"SQL\")])\n",
    "\n",
    "text_5 = \"Experience with SQL and NoSQL databases.\"\n",
    "doc_5 = nlp(text_5)\n",
    "\n",
    "sql_only = []\n",
    "for _, start, end in sql_matcher(doc_5):\n",
    "    if doc_5[start:end].text.lower() == \"sql\":\n",
    "        sql_only.append(\"sql\")\n",
    "\n",
    "sql_only = normalize_skills(sql_only)\n",
    "sql_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef88f59-90a7-4cf7-91af-fa53341135ff",
   "metadata": {},
   "source": [
    "### 15. Given a resume and a job description, extract skills separately and output them as two different JSON objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7071c0e-04e4-4a04-bc54-e7604852722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume skills: {'technical_skills': ['nlp', 'python', 'sql'], 'soft_skills': ['communication']}\n",
      "job_skills: {'technical_skills': ['machine learning', 'sql'], 'soft_skills': ['leadership', 'teamwork']}\n"
     ]
    }
   ],
   "source": [
    "resume_text = \"Python, SQL, NLP, and strong communication skills.\"\n",
    "job_description = \"Looking for Machine Learning, SQL, teamwork, and leadership.\"\n",
    "\n",
    "resume_skills = extract_all_skills(resume_text)\n",
    "job_skills = extract_all_skills(job_description)\n",
    "\n",
    "print(\"Resume skills:\",resume_skills)\n",
    "print(\"job_skills:\",job_skills)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
